{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-Data\" data-toc-modified-id=\"Reading-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Reading Data</a></span></li><li><span><a href=\"#Data-pre-processing\" data-toc-modified-id=\"Data-pre-processing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data pre-processing</a></span></li><li><span><a href=\"#Splitting-data-75-25(train-test)\" data-toc-modified-id=\"Splitting-data-75-25(train-test)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Splitting data 75-25(train-test)</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#SGD-model-Hyperparameter-tuning\" data-toc-modified-id=\"SGD-model-Hyperparameter-tuning-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>SGD model Hyperparameter tuning</a></span></li><li><span><a href=\"#SVC-model\" data-toc-modified-id=\"SVC-model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>SVC model</a></span></li><li><span><a href=\"#Random-Forest-model\" data-toc-modified-id=\"Random-Forest-model-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Random Forest model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('cleaned_mar_eng1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4977 entries, 0 to 4976\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   TEXT       4977 non-null   object\n",
      " 1   Sentiment  4977 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 77.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEXT', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2404\n",
       "2    1712\n",
       "1     861\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words = 'english', ngram_range = (1,1),tokenizer = token.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC-FEM\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts = cv.fit_transform(dataset.TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data 75-25(train-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.33%\n"
     ]
    }
   ],
   "source": [
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.01%\n"
     ]
    }
   ],
   "source": [
    "#ngram-1\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['TEXT'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size = 0.25, random_state = 5)\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.33%\n"
     ]
    }
   ],
   "source": [
    "#ngram-2\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['TEXT'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size = 0.25, random_state = 5)\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.54%\n"
     ]
    }
   ],
   "source": [
    "#with this ngram we are getting 60+ accuracy\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['TEXT'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size = 0.25, random_state = 5)\n",
    "\n",
    "#defining and compiling the model using ComplementNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "#fitting the model\n",
    "CNB = ComplementNB()\n",
    "CNB.fit(X_train, Y_train)\n",
    "\n",
    "#evaluating the model\n",
    "accuracy_score = metrics.accuracy_score(CNB.predict(X_test), Y_test)\n",
    "\n",
    "print(str('{:4.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB accuracy = 65.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train.todense(), Y_train)\n",
    "accuracy_score = metrics.accuracy_score(CNB.predict(X_test),Y_test)\n",
    "\n",
    "print('GNB accuracy = ' + str('{:4.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB accuracy = 53.57%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, Y_train)\n",
    "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(X_test),Y_test)\n",
    "print('BNB accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_mnb = 58.15%\n",
      "accuracy_score_bnb = 53.98%\n",
      "accuracy_score_cnb = 64.18%\n",
      "accuracy_score_gnb = 58.07%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(dataset['TEXT'])\n",
    "\n",
    "#splitting data in test and training\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, dataset['Sentiment'], test_size = 0.25, random_state = 5)\n",
    "\n",
    "#defining the model\n",
    "MNB.fit(x_train, y_train)\n",
    "accuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\n",
    "print('accuracy_score_mnb = '+str('{:4.2f}'.format(accuracy_score_mnb*100))+'%')\n",
    "\n",
    "BNB.fit(x_train, y_train)\n",
    "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\n",
    "print('accuracy_score_bnb = '+str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n",
    "\n",
    "CNB.fit(x_train, y_train)\n",
    "accuracy_score_cnb = metrics.accuracy_score(CNB.predict(x_test), y_test)\n",
    "print('accuracy_score_cnb = '+str('{:4.2f}'.format(accuracy_score_cnb*100))+'%')\n",
    "\n",
    "GNB.fit(x_train.todense(), y_train)\n",
    "accuracy_score_gnb = metrics.accuracy_score(GNB.predict(x_test.todense()), y_test)\n",
    "print('accuracy_score_gnb = '+str('{:4.2f}'.format(accuracy_score_gnb*100))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc = 69.64%\n",
      "accuracy_score_lsvc_cv = 68.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "SGDC = SGDClassifier()\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "#on TF-IDF data\n",
    "#LSVC.fit(x_train, y_train)\n",
    "#accuracy_score_lsvc = metrics.accuracy_score(LSVC.predict(x_test), y_test)\n",
    "#print('accuracy_score_lsvc = '+str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')\n",
    "\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "\n",
    "#on countvectorize data\n",
    "LSVC.fit(X_train, Y_train)\n",
    "accuracy_score_lsvc_CV = metrics.accuracy_score(LSVC.predict(X_test), Y_test)\n",
    "print('accuracy_score_lsvc_cv = '+str('{:4.2f}'.format(accuracy_score_lsvc_CV*100))+'%')\n",
    "\n",
    "#SGDC.fit(X_train, Y_train)\n",
    "#accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(X_test), Y_test)\n",
    "#print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.43      0.52       213\n",
      "           2       0.58      0.73      0.65       425\n",
      "           3       0.78      0.74      0.76       607\n",
      "\n",
      "    accuracy                           0.68      1245\n",
      "   macro avg       0.67      0.63      0.64      1245\n",
      "weighted avg       0.69      0.68      0.68      1245\n",
      "\n",
      "\n",
      "confusion matrix : \n",
      " [[ 91  85  37]\n",
      " [ 25 309  91]\n",
      " [ 21 137 449]]\n",
      "\n",
      "accuracy: \n",
      " 0.6819277108433734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "pred = LSVC.predict(X_test)\n",
    "print(classification_report(Y_test, pred))\n",
    "print()\n",
    "print(\"confusion matrix : \\n\", confusion_matrix(Y_test, pred) )\n",
    "print()\n",
    "print(\"accuracy: \\n\", accuracy_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.53      0.58       213\n",
      "           2       0.60      0.68      0.64       425\n",
      "           3       0.79      0.76      0.78       607\n",
      "\n",
      "    accuracy                           0.70      1245\n",
      "   macro avg       0.68      0.66      0.67      1245\n",
      "weighted avg       0.70      0.70      0.70      1245\n",
      "\n",
      "\n",
      "confusion matrix : \n",
      " [[113  75  25]\n",
      " [ 38 291  96]\n",
      " [ 26 118 463]]\n",
      "\n",
      "accuracy: \n",
      " 0.6963855421686747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "pred = SGDC.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print()\n",
    "print(\"confusion matrix : \\n\", confusion_matrix(y_test, pred) )\n",
    "print()\n",
    "print(\"accuracy: \\n\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=350, max_depth=15, random_state=1, min_samples_leaf=1)\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6   2 205]\n",
      " [  2  25 398]\n",
      " [  2   1 604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.03      0.05       213\n",
      "           2       0.89      0.06      0.11       425\n",
      "           3       0.50      1.00      0.67       607\n",
      "\n",
      "    accuracy                           0.51      1245\n",
      "   macro avg       0.66      0.36      0.28      1245\n",
      "weighted avg       0.65      0.51      0.37      1245\n",
      "\n",
      "0.5100401606425703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "predictions = text_classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\prashita\\anacondamay\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\prashita\\anacondamay\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82 101  30]\n",
      " [ 27 322  76]\n",
      " [ 19 141 447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.38      0.48       213\n",
      "           2       0.57      0.76      0.65       425\n",
      "           3       0.81      0.74      0.77       607\n",
      "\n",
      "    accuracy                           0.68      1245\n",
      "   macro avg       0.67      0.63      0.63      1245\n",
      "weighted avg       0.70      0.68      0.68      1245\n",
      "\n",
      "0.6835341365461848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['clf']\n",
      "parameters:\n",
      "{'clf__learning_rate': (0.1, 0.3, 0.5, 0.8),\n",
      " 'clf__max_depth': (5, 10),\n",
      " 'clf__n_estimators': (200, 300, 400, 500)}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 432.386s\n",
      "\n",
      "Best score: 0.663\n",
      "Best parameters set:\n",
      "\tclf__learning_rate: 0.3\n",
      "\tclf__max_depth: 5\n",
      "\tclf__n_estimators: 300\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for XGBoost\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor \n",
    "# with a simple classifier (logistic regression)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    #('vect', CountVectorizer()),  #http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "    #('tfidf', TfidfTransformer()), #ignore for now\n",
    "    ('clf', XGBClassifier(base_score=0.5, booster='gbtree',min_child_weight=1, gamma=0, objective= 'multi:softprob', seed=27)) \n",
    "])\n",
    "\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # jgs 'vect__max_features': (None, 500, 5000, 10000, 50000),\n",
    "    # jgs 'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__n_estimators': ( 200, 300, 400, 500),\n",
    "    'clf__learning_rate': (0.1, 0.3, 0.5, 0.8),\n",
    "    'clf__max_depth': (5, 10)\n",
    "    #'clf__loss': ('log', 'hinge'),  #hinge linear SVM\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=300, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=27, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=27, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "classifier = XGBClassifier(base_score=0.5, booster='gbtree',min_child_weight=1,\n",
    "                           gamma=0, objective= 'multi:softprob', seed=27, \n",
    "                           learning_rate = 0.3, max_depth = 5, n_estimators = 300)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  91  30]\n",
      " [ 35 311  79]\n",
      " [ 19 129 459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.43      0.51       213\n",
      "           2       0.59      0.73      0.65       425\n",
      "           3       0.81      0.76      0.78       607\n",
      "\n",
      "    accuracy                           0.69      1245\n",
      "   macro avg       0.67      0.64      0.65      1245\n",
      "weighted avg       0.70      0.69      0.69      1245\n",
      "\n",
      "0.6923694779116466\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(accuracy_score(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Convert a number to a percent.    \n",
    "def pct(x):\n",
    "    return round(100*x,1)\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "# Joining the scaled numeric and categorical features.\n",
    "\n",
    "full_pipeline =Pipeline([\n",
    "     ('vectorizer', CountVectorizer())\n",
    "     #('to_dense', DenseTransformer())\n",
    "])     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A Function to execute the grid search and record the results.\n",
    "def ConductGridSearch(X_train, y_train, X_test, y_test, i=0, prefix='', n_jobs=-1,verbose=1):\n",
    "    # Create a list of classifiers for our grid search experiment\n",
    "    classifiers = [\n",
    "        ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "        ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "        ('Naive Bayes', GaussianNB()),\n",
    "        ('Support Vector', SVC(random_state=42)),\n",
    "        ('Stochastic GD', SGDClassifier(random_state=42)),\n",
    "        ('RandomForest', RandomForestClassifier()),\n",
    "    ]\n",
    "\n",
    "    # Arrange grid search parameters for each classifier\n",
    "    params_grid = {\n",
    "        'Logistic Regression': {\n",
    "            'penalty': ('l1', 'l2'),\n",
    "            'tol': (0.0001, 0.00001, 0.0000001), \n",
    "            'C': (10, 1, 0.1, 0.01),\n",
    "        },\n",
    "        \n",
    "        'Naive Bayes': {},\n",
    "        'Support Vector' : {\n",
    "            'kernel': ('rbf', 'poly'),     \n",
    "            'degree': (1, 2, 3, 4, 5),\n",
    "            'C': (10, 1, 0.1, 0.01),\n",
    "        },\n",
    "        'Stochastic GD': {\n",
    "            'loss': ('hinge', 'perceptron', 'log'),\n",
    "            'penalty': ('l1', 'l2', 'elasticnet'),\n",
    "            'tol': (0.0001, 0.00001, 0.0000001), \n",
    "            'alpha': (0.1, 0.01, 0.001, 0.0001), \n",
    "        },\n",
    "        'RandomForest':  {\n",
    "            'max_depth': [9, 15, 22, 26, 30],\n",
    "            'max_features': [1, 3, 5],\n",
    "            'min_samples_split': [5, 10, 15],\n",
    "            'min_samples_leaf': [3, 5, 10],\n",
    "            'bootstrap': [False],\n",
    "            'n_estimators':[20, 80, 150, 200, 300]},\n",
    "    }\n",
    "    \n",
    "    for (name, classifier) in classifiers:\n",
    "        i += 1\n",
    "        # Print classifier and parameters\n",
    "        print('****** START',prefix, name,'*****')\n",
    "        parameters = params_grid[name]\n",
    "        print(\"Parameters:\")\n",
    "        for p in sorted(parameters.keys()):\n",
    "            print(\"\\t\"+str(p)+\": \"+ str(parameters[p]))\n",
    "        \n",
    "        # generate the pipeline\n",
    "        full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"predictor\", classifier)\n",
    "        ])\n",
    "        \n",
    "        # Execute the grid search\n",
    "        params = {}\n",
    "        for p in parameters.keys():\n",
    "            pipe_key = 'predictor__'+str(p)\n",
    "            params[pipe_key] = parameters[p] \n",
    "        grid_search = GridSearchCV(full_pipeline_with_predictor, params, scoring='accuracy', cv=5, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "                \n",
    "        # Best estimator score\n",
    "        best_train = pct(grid_search.best_score_)\n",
    "\n",
    "        # Best estimator fitting time\n",
    "        start = time()\n",
    "        grid_search.best_estimator_.fit(x_train, y_train)\n",
    "        train_time = round(time() - start, 4)\n",
    "\n",
    "        # Best estimator prediction time\n",
    "        start = time()\n",
    "        best_test_accuracy = pct(grid_search.best_estimator_.score(X_test, y_test))\n",
    "        test_time = round(time() - start, 4)\n",
    "\n",
    "        # Generate 30 training accuracy scores with the best estimator and 30-split CV\n",
    "        \n",
    "        #==================================================#\n",
    "        best_train_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=cv30Splits)\n",
    "        best_train_accuracy = pct(np.mean(best_train_scores))\n",
    "        #==================================================#    \n",
    "       \n",
    "        # Conduct t-test with baseline logit (control) and best estimator (experiment)\n",
    "        #(t_stat, p_value) = stats.ttest_rel(logit_scores, best_train_scores)\n",
    "        \n",
    "        # Collect the best parameters found by the grid search\n",
    "        print(\"Best Parameters:\")\n",
    "        best_parameters = grid_search.best_estimator_.get_params()\n",
    "        param_dump = []\n",
    "        for param_name in sorted(params.keys()):\n",
    "            param_dump.append((param_name, best_parameters[param_name]))\n",
    "            print(\"\\t\"+str(param_name)+\": \" + str(best_parameters[param_name]))\n",
    "        print(\"****** FINISH\",prefix,name,\" *****\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Record the results\n",
    "        results.loc[i] = [prefix+name, best_train_accuracy, best_test_accuracy, round(p_value,5), train_time, test_time, json.dumps(param_dump)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD model Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__loss': ('log', 'hinge'),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet')}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.829s\n",
      "\n",
      "Best score: 0.635\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'elasticnet'\n",
      "Wall time: 834 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.6s finished\n",
      "C:\\Users\\Prashita\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor \n",
    "# with a simple classifier (logistic regression)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  #http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "    #('tfidf', TfidfTransformer()), #ignore for now\n",
    "    ('clf', SGDClassifier(max_iter=5)) \n",
    "])\n",
    "\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # jgs 'vect__max_features': (None, 500, 5000, 10000, 50000),\n",
    "    # jgs 'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "    #'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "    'clf__loss': ('log', 'hinge'),  #hinge linear SVM\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(dataset.TEXT, dataset.Sentiment)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (10, 1, 0.1, 0.01),\n",
      " 'clf__degree': (1, 2, 3, 4, 5),\n",
      " 'clf__kernel': ('rbf', 'poly')}\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 31.370s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__degree: 1\n",
      "\tclf__kernel: 'rbf'\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This code is adopted  and has been modified from \n",
    "#\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor \n",
    "# with a simple classifier (logistic regression)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  #http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "    #('tfidf', TfidfTransformer()), #ignore for now\n",
    "    ('clf', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # jgs 'vect__max_features': (None, 500, 5000, 10000, 50000),\n",
    "    'clf__kernel': ('rbf', 'poly'),     \n",
    "    'clf__degree': (1, 2, 3, 4, 5),\n",
    "    'clf__C': (10, 1, 0.1, 0.01)\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(dataset.TEXT, dataset.Sentiment)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__bootstrap': [False],\n",
      " 'clf__max_depth': [9, 15, 22, 26, 30],\n",
      " 'clf__max_features': [1, 3, 5],\n",
      " 'clf__min_samples_leaf': [3, 5, 10],\n",
      " 'clf__min_samples_split': [5, 10, 15],\n",
      " 'clf__n_estimators': [20, 80, 150, 200, 300]}\n",
      "Fitting 3 folds for each of 675 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 190.587s\n",
      "\n",
      "Best score: 0.550\n",
      "Best parameters set:\n",
      "\tclf__bootstrap: False\n",
      "\tclf__max_depth: 9\n",
      "\tclf__max_features: 1\n",
      "\tclf__min_samples_leaf: 3\n",
      "\tclf__min_samples_split: 5\n",
      "\tclf__n_estimators: 20\n",
      "Wall time: 3min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2025 out of 2025 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This code is adopted  and has been modified from \n",
    "#\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor \n",
    "# with a simple classifier (logistic regression)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  #http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "    #('tfidf', TfidfTransformer()), #ignore for now\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # jgs 'vect__max_features': (None, 500, 5000, 10000, 50000),\n",
    "    'clf__max_depth': [9, 15, 22, 26, 30],\n",
    "    'clf__max_features': [1, 3, 5],\n",
    "    'clf__min_samples_split': [5, 10, 15],\n",
    "    'clf__min_samples_leaf': [3, 5, 10],\n",
    "    'clf__bootstrap': [False],\n",
    "    'clf__n_estimators':[20, 80, 150, 200, 300]\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(dataset.TEXT, dataset.Sentiment)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
